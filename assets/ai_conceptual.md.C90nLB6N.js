/* empty css                                                               */import{_ as a,c as e,o as t,aa as r}from"./chunks/framework.CeN9Tan-.js";const q=JSON.parse('{"title":"概念知识","description":null,"frontmatter":{"description":null,"layoutClass":"fuye-single-page-layout","outline":[2,3,4]},"headers":[],"relativePath":"ai/conceptual.md","filePath":"ai/conceptual.md"}'),o={name:"ai/conceptual.md"},h=r('<h1 id="概念知识" tabindex="-1">概念知识 <a class="header-anchor" href="#概念知识" aria-label="Permalink to &quot;概念知识&quot;">​</a></h1><h2 id="a" tabindex="-1">A <a class="header-anchor" href="#a" aria-label="Permalink to &quot;A&quot;">​</a></h2><h2 id="b" tabindex="-1">B <a class="header-anchor" href="#b" aria-label="Permalink to &quot;B&quot;">​</a></h2><h2 id="c" tabindex="-1">C <a class="header-anchor" href="#c" aria-label="Permalink to &quot;C&quot;">​</a></h2><h3 id="chatgpt" tabindex="-1">ChatGPT <a class="header-anchor" href="#chatgpt" aria-label="Permalink to &quot;ChatGPT&quot;">​</a></h3><p>ChatGPT，它是一款用于聊天的产品，而它背后使用的大语言模型是<a href="#gpt">GPT</a>。</p><h3 id="cloud-desktop" tabindex="-1">Cloud Desktop <a class="header-anchor" href="#cloud-desktop" aria-label="Permalink to &quot;Cloud Desktop&quot;">​</a></h3><p>云桌面。可以使用被人打包好的环境和软件，这个打包好的东西叫做<a href="#image">镜像</a>。</p><h3 id="closed-source-model" tabindex="-1">Closed-source Model <a class="header-anchor" href="#closed-source-model" aria-label="Permalink to &quot;Closed-source Model&quot;">​</a></h3><p>闭源模型。开放模型权重，可以下载到自己电脑部署的模型，叫做开源模型。但是现在开源模型只是开放了权重，而不开放训练代码和训练数据。所以，准确的说叫<a href="#open-weight-model">开放权重模型</a>。</p><h3 id="connectionism" tabindex="-1">Connectionism <a class="header-anchor" href="#connectionism" aria-label="Permalink to &quot;Connectionism&quot;">​</a></h3><p>联结主义，先什么都不管，弄一个非常复杂的函数，然后根据计算出来的预测值与真实值的误差，不断调整里面的位置参数，这个函数叫住<a href="#model">模型</a>。</p><h3 id="context" tabindex="-1">Context <a class="header-anchor" href="#context" aria-label="Permalink to &quot;Context&quot;">​</a></h3><p>上下文。不同的模型有不同的上下文的长度限制，越大就越能记住前面的信息，上下文从另外一个角度理解也可以叫<a href="#prompt">提示词</a>。</p><h2 id="d" tabindex="-1">D <a class="header-anchor" href="#d" aria-label="Permalink to &quot;D&quot;">​</a></h2><h2 id="e" tabindex="-1">E <a class="header-anchor" href="#e" aria-label="Permalink to &quot;E&quot;">​</a></h2><h3 id="emergence" tabindex="-1">Emergence <a class="header-anchor" href="#emergence" aria-label="Permalink to &quot;Emergence&quot;">​</a></h3><p>涌现，大语言模型爆火的产品是2023年<a href="#chatgpt">ChatGPT</a>。</p><h2 id="f" tabindex="-1">F <a class="header-anchor" href="#f" aria-label="Permalink to &quot;F&quot;">​</a></h2><h3 id="fully-open-source-model" tabindex="-1">Fully Open-source Model <a class="header-anchor" href="#fully-open-source-model" aria-label="Permalink to &quot;Fully Open-source Model&quot;">​</a></h3><p>完全开源。有了模型、权重，可以下载到本地进行部署和使用了，很少有人要重新训练它。不依赖他人的服务，而是把模型下载到本地进行使用的过程叫做<a href="#private-deployment">私有化部署</a>。</p><h3 id="function" tabindex="-1">Function <a class="header-anchor" href="#function" aria-label="Permalink to &quot;Function&quot;">​</a></h3><p>函数，万物皆函数，<code>x -&gt; y =&gt; f(x) = y</code>。早期人们用符号主义的思想找到精确的<a href="#function">函数</a>，试图解释一切原理叫做<a href="#symbolish">符号主义</a>。</p><h3 id="fine-tuning" tabindex="-1">Fine-tuning <a class="header-anchor" href="#fine-tuning" aria-label="Permalink to &quot;Fine-tuning&quot;">​</a></h3><p>微调，参数调整好后，根据参数的输入计算输出结果的过程，叫做<a href="#inference">推理</a>。</p><h2 id="g" tabindex="-1">G <a class="header-anchor" href="#g" aria-label="Permalink to &quot;G&quot;">​</a></h2><h3 id="generative-ai" tabindex="-1">Generative AI <a class="header-anchor" href="#generative-ai" aria-label="Permalink to &quot;Generative AI&quot;">​</a></h3><p>生成式AI。当然除了文本，也包含图像、声音、视频等。这里每一个分割成最小粒度的词叫做<a href="#token">Token</a>。</p><h3 id="gpt" tabindex="-1">GPT <a class="header-anchor" href="#gpt" aria-label="Permalink to &quot;GPT&quot;">​</a></h3><p>Generative Pre-trained Transformer，它是一个系列，开发这个模型的公司是 <a href="#产品-模型-公司">OpenAI</a>。</p><h2 id="h" tabindex="-1">H <a class="header-anchor" href="#h" aria-label="Permalink to &quot;H&quot;">​</a></h2><h2 id="i" tabindex="-1">I <a class="header-anchor" href="#i" aria-label="Permalink to &quot;I&quot;">​</a></h2><h3 id="image" tabindex="-1">Image <a class="header-anchor" href="#image" aria-label="Permalink to &quot;Image&quot;">​</a></h3><p>镜像。</p><p>大语言模型的本质就是一个大函数，根据前面的一句话持续不断地计算下一个词是什么，这种基于输入内容自动生成新内容的人工智能系统，叫做<a href="#generative-ai">生成式AI</a>。</p><h3 id="inference" tabindex="-1">Inference <a class="header-anchor" href="#inference" aria-label="Permalink to &quot;Inference&quot;">​</a></h3><p>推理。前面这些概念在大模型时代到来之后，逐渐变得火热起来，当模型参数量足够大的时候，对话能力有了质的提升，产生了一定的推理能力。这种量变引起质变而突然出现的且之前没有能力的现象，叫做<a href="#emergence">涌现</a>。</p><h2 id="j" tabindex="-1">J <a class="header-anchor" href="#j" aria-label="Permalink to &quot;J&quot;">​</a></h2><h2 id="k" tabindex="-1">K <a class="header-anchor" href="#k" aria-label="Permalink to &quot;K&quot;">​</a></h2><h2 id="l" tabindex="-1">L <a class="header-anchor" href="#l" aria-label="Permalink to &quot;L&quot;">​</a></h2><h3 id="large-model" tabindex="-1">Large Model <a class="header-anchor" href="#large-model" aria-label="Permalink to &quot;Large Model&quot;">​</a></h3><p>大模型，用于自然语言处理的大模型叫做<a href="#large-language-model">大语言模型</a>。</p><h3 id="large-language-model" tabindex="-1">Large Language Model <a class="header-anchor" href="#large-language-model" aria-label="Permalink to &quot;Large Language Model&quot;">​</a></h3><p>大语言模型，调整参数的过程叫做模型的<a href="#training">训练</a>。</p><h2 id="m" tabindex="-1">M <a class="header-anchor" href="#m" aria-label="Permalink to &quot;M&quot;">​</a></h2><h3 id="model" tabindex="-1">Model <a class="header-anchor" href="#model" aria-label="Permalink to &quot;Model&quot;">​</a></h3><p>模型，模型里的参数叫做<a href="#weight">权重</a>。</p><h2 id="n" tabindex="-1">N <a class="header-anchor" href="#n" aria-label="Permalink to &quot;N&quot;">​</a></h2><h2 id="o" tabindex="-1">O <a class="header-anchor" href="#o" aria-label="Permalink to &quot;O&quot;">​</a></h2><h3 id="open-weight-model" tabindex="-1">Open-weight Model <a class="header-anchor" href="#open-weight-model" aria-label="Permalink to &quot;Open-weight Model&quot;">​</a></h3><p>开放权重，比如DeepSeek、LLaMA等。不但开放了模型结构和权重，还开放了训练代码的模型，叫做<a href="#fully-open-source-model">完全开源</a>。</p><h2 id="p" tabindex="-1">P <a class="header-anchor" href="#p" aria-label="Permalink to &quot;P&quot;">​</a></h2><h3 id="pretraining" tabindex="-1">Pretraining <a class="header-anchor" href="#pretraining" aria-label="Permalink to &quot;Pretraining&quot;">​</a></h3><p>预训练，基于预训练的模型继续训练，让模型学习具体任务的方式叫做<a href="#fine-tuning">微调</a>。</p><h3 id="prompt" tabindex="-1">Prompt <a class="header-anchor" href="#prompt" aria-label="Permalink to &quot;Prompt&quot;">​</a></h3><p>提示词。</p><h3 id="private-deployment" tabindex="-1">Private Deployment <a class="header-anchor" href="#private-deployment" aria-label="Permalink to &quot;Private Deployment&quot;">​</a></h3><p>私有化部署。私有化部署依赖很多复杂的环境置，就是要装很多依赖的软件和工具包，而且还需要性能较为强劲的GPU的支持，对于仅仅需要尝鲜的个人，专门为此去买台电脑不太合适，就有了<a href="#cloud-desktop">云桌面</a>。</p><h2 id="q" tabindex="-1">Q <a class="header-anchor" href="#q" aria-label="Permalink to &quot;Q&quot;">​</a></h2><h2 id="r" tabindex="-1">R <a class="header-anchor" href="#r" aria-label="Permalink to &quot;R&quot;">​</a></h2><h2 id="s" tabindex="-1">S <a class="header-anchor" href="#s" aria-label="Permalink to &quot;S&quot;">​</a></h2><h3 id="symbolish" tabindex="-1">Symbolish <a class="header-anchor" href="#symbolish" aria-label="Permalink to &quot;Symbolish&quot;">​</a></h3><p>符号主义后来遇到了瓶颈，后来人们转用<a href="#connectionism">联结主义</a>思想。</p><h2 id="t" tabindex="-1">T <a class="header-anchor" href="#t" aria-label="Permalink to &quot;T&quot;">​</a></h2><h3 id="token" tabindex="-1">Token <a class="header-anchor" href="#token" aria-label="Permalink to &quot;Token&quot;">​</a></h3><p>Token。对话时，所有给到大模型的信息叫做<a href="#context">上下文</a>。</p><h3 id="training" tabindex="-1">Training <a class="header-anchor" href="#training" aria-label="Permalink to &quot;Training&quot;">​</a></h3><p>训练，事先训练好一个基础模型的方式叫做<a href="#pretraining">预训练</a>。</p><h2 id="u" tabindex="-1">U <a class="header-anchor" href="#u" aria-label="Permalink to &quot;U&quot;">​</a></h2><h2 id="v" tabindex="-1">V <a class="header-anchor" href="#v" aria-label="Permalink to &quot;V&quot;">​</a></h2><h2 id="w" tabindex="-1">W <a class="header-anchor" href="#w" aria-label="Permalink to &quot;W&quot;">​</a></h2><h3 id="weight" tabindex="-1">Weight <a class="header-anchor" href="#weight" aria-label="Permalink to &quot;Weight&quot;">​</a></h3><p>权重，如果模型里的参数量特别大，就叫做<a href="#large-model">大模型</a>。</p><h2 id="x" tabindex="-1">X <a class="header-anchor" href="#x" aria-label="Permalink to &quot;X&quot;">​</a></h2><h2 id="y" tabindex="-1">Y <a class="header-anchor" href="#y" aria-label="Permalink to &quot;Y&quot;">​</a></h2><h2 id="z" tabindex="-1">Z <a class="header-anchor" href="#z" aria-label="Permalink to &quot;Z&quot;">​</a></h2><h2 id="产品-模型-公司" tabindex="-1">产品-模型-公司 <a class="header-anchor" href="#产品-模型-公司" aria-label="Permalink to &quot;产品-模型-公司&quot;">​</a></h2><h3 id="国内" tabindex="-1">国内 <a class="header-anchor" href="#国内" aria-label="Permalink to &quot;国内&quot;">​</a></h3><table><thead><tr><th>产品</th><th>模型</th><th>公司</th></tr></thead><tbody><tr><td>DeepSeek Chat</td><td>DeepSeek-V2</td><td>深势科技</td></tr><tr><td>通义千问</td><td>Qwen 系列</td><td>阿里</td></tr><tr><td>腾讯混元助手</td><td>混元大模型</td><td>腾讯</td></tr><tr><td>豆包</td><td>词言、云雀等</td><td>字节跳动</td></tr><tr><td>Kimi Chat</td><td>Moonshot V1/V2（自研）</td><td>月之暗面</td></tr></tbody></table><h3 id="国外" tabindex="-1">国外 <a class="header-anchor" href="#国外" aria-label="Permalink to &quot;国外&quot;">​</a></h3><table><thead><tr><th>产品</th><th>模型</th><th>公司</th></tr></thead><tbody><tr><td><a href="#chatgpt">ChatGPT</a></td><td>GPT-3.5、GPT-4、GPT-4 Turbo</td><td><a href="#openai">OpenAI</a></td></tr><tr><td>Copilot</td><td>GPT-4</td><td>GitHub + OpenAI</td></tr><tr><td>Claude</td><td>Claude2/3</td><td>Anthropic</td></tr><tr><td>Gemini Chat</td><td>Gemini 1.5（前身 PaLM）</td><td>Google DeepMind</td></tr><tr><td>Perplexity</td><td>Mixtral / Claude / GPT-4(多模型)</td><td>Perplexity（聚合型）</td></tr><tr><td>Poe</td><td>GPT / Claude / LLaMA / Gemini等</td><td>Quora（聚合型）</td></tr></tbody></table><p>一个模型需要还有训练它的代码，有了代码就可以训练出一组权重，有了权重就可以推理，就可以对外提供服务了。不开放源代码，也不开放权重，只对外提供服务的模型叫做<a href="#closed-source-model">闭源模型</a>。如 ChatGPT、Claude、Gemini等。</p>',82),i=[h];function l(n,d,c,s,u,b){return t(),e("div",null,i)}const f=a(o,[["render",l]]);export{q as __pageData,f as default};
